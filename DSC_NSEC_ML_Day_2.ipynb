{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSC NSEC ML Day 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating KFold Dataset"
      ],
      "metadata": {
        "id": "poxrmelH34hO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "4e8v0ceulA2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LasscLPGxcPQ"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/rishiraj/datasets/raw/main/tabular-playground-series-feb-2021.zip\n",
        "!unzip tabular-playground-series-feb-2021.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection"
      ],
      "metadata": {
        "id": "IoKvWIt6JFF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/train.csv\")"
      ],
      "metadata": {
        "id": "TMwbF7xVKPSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "IjKsnWPVKXOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.target.hist()"
      ],
      "metadata": {
        "id": "mlvLXSJuKk1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "rNQz9Ul6Pt1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"kfold\"] = -1"
      ],
      "metadata": {
        "id": "dwxfGr5UK7t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train)):\n",
        "    df_train.loc[valid_indicies, \"kfold\"] = fold"
      ],
      "metadata": {
        "id": "p-BdZUHcLSeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv(\"train_folds.csv\", index=False)"
      ],
      "metadata": {
        "id": "dPax3KazLYUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "F6vbCO5dLcKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.kfold.value_counts()"
      ],
      "metadata": {
        "id": "civorkXxLucV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[df_train.kfold==0].target.hist()"
      ],
      "metadata": {
        "id": "VNNIrRAtMZfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Base Model"
      ],
      "metadata": {
        "id": "i3dEWCxX4K3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "7DqVvdQ-NLkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_folds.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")"
      ],
      "metadata": {
        "id": "WdBjjT2YQlLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
        "object_cols = [col for col in useful_features if 'cat' in col]\n",
        "df_test = df_test[useful_features]"
      ],
      "metadata": {
        "id": "XQbjuOjEQyg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
        "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
        "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
        "    \n",
        "    model = XGBRegressor(random_state=fold, n_jobs=4)\n",
        "    # model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n",
        "    model.fit(xtrain, ytrain)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_predictions.append(test_preds)\n",
        "    print(fold, mean_squared_error(yvalid, preds_valid, squared=False))"
      ],
      "metadata": {
        "id": "88Va_G6wQ6en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.mean(np.column_stack(final_predictions), axis=1)"
      ],
      "metadata": {
        "id": "1s6AdHCLRI_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.target = preds\n",
        "sample_submission.to_csv(\"submission_0.csv\", index=False)"
      ],
      "metadata": {
        "id": "3rklbSSmRdsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Hyperparameter Optimized Model"
      ],
      "metadata": {
        "id": "5K6cLJ194SKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "metadata": {
        "id": "RJqgREZNcAnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_folds.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "\n",
        "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
        "object_cols = [col for col in useful_features if col.startswith(\"cat\")]\n",
        "df_test = df_test[useful_features]"
      ],
      "metadata": {
        "id": "-mJOng6zc6N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(trial):\n",
        "    fold = 0\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n",
        "    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
        "    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
        "    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
        "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 1, 7)\n",
        "\n",
        "    xtrain = df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "\n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "\n",
        "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
        "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
        "\n",
        "    model = XGBRegressor(\n",
        "        random_state=42,\n",
        "        tree_method=\"gpu_hist\",\n",
        "        gpu_id=0,\n",
        "        predictor=\"gpu_predictor\",\n",
        "        n_estimators=7000,\n",
        "        learning_rate=learning_rate,\n",
        "        reg_lambda=reg_lambda,\n",
        "        reg_alpha=reg_alpha,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        max_depth=max_depth,\n",
        "    )\n",
        "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "oMvJjEkGdeaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(run, n_trials=5)"
      ],
      "metadata": {
        "id": "P1nFdP6EeLYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "id": "w96-dk0Ad4WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = []\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
        "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
        "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
        "    \n",
        "    params = {'colsample_bytree': 0.3424344480176586,\n",
        "              'learning_rate': 0.05415032702941656,\n",
        "              'max_depth': 2,\n",
        "              'reg_alpha': 2.917560190606865,\n",
        "              'reg_lambda': 0.010988482071288476,\n",
        "              'subsample': 0.9092622969152414}\n",
        "    \n",
        "    model = XGBRegressor(\n",
        "        random_state=0, \n",
        "        #tree_method='gpu_hist',\n",
        "        #gpu_id=0,\n",
        "        #predictor=\"gpu_predictor\",\n",
        "        n_estimators=5000,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_predictions.append(test_preds)\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))"
      ],
      "metadata": {
        "id": "qGrfRPFult4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.mean(np.column_stack(final_predictions), axis=1)\n",
        "sample_submission.target = preds\n",
        "sample_submission.to_csv(\"submission_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "-YP69HozlzFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blending"
      ],
      "metadata": {
        "id": "ecvQKnjZ5BgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "pTAVpjFQ5Osj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_folds.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "\n",
        "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
        "object_cols = [col for col in useful_features if 'cat' in col]\n",
        "df_test = df_test[useful_features]\n",
        "\n",
        "final_test_predictions = []\n",
        "final_valid_predictions = {}\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "    \n",
        "    valid_ids = xvalid.id.values.tolist()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
        "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
        "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
        "    \n",
        "    params = {\n",
        "        'random_state': 1, \n",
        "        'booster': 'gbtree',\n",
        "        'n_estimators': 10000,\n",
        "        'learning_rate': 0.03628302216953097,\n",
        "        'reg_lambda': 0.0008746338866473539,\n",
        "        'reg_alpha': 23.13181079976304,\n",
        "        'subsample': 0.7875490025178415,\n",
        "        'colsample_bytree': 0.11807135201147481,\n",
        "        'max_depth': 3\n",
        "    }\n",
        "    \n",
        "    model = XGBRegressor(\n",
        "        n_jobs=4,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_test_predictions.append(test_preds)\n",
        "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))\n",
        "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
        "final_valid_predictions.columns = [\"id\", \"pred_1\"]\n",
        "final_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)\n",
        "\n",
        "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
        "sample_submission.columns = [\"id\", \"pred_1\"]\n",
        "sample_submission.to_csv(\"test_pred_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "DLv1a3cD5ZEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_folds.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "\n",
        "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
        "object_cols = [col for col in useful_features if 'cat' in col]\n",
        "df_test = df_test[useful_features]\n",
        "\n",
        "final_test_predictions = []\n",
        "final_valid_predictions = {}\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "    \n",
        "    valid_ids = xvalid.id.values.tolist()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
        "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
        "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
        "    \n",
        "    params = {\n",
        "        'learning_rate': 0.07853392035787837,\n",
        "        'reg_lambda': 1.7549293092194938e-05,\n",
        "        'reg_alpha': 14.68267919457715, \n",
        "        'subsample': 0.8031450486786944, \n",
        "        'colsample_bytree': 0.170759104940733, \n",
        "        'max_depth': 3\n",
        "    }\n",
        "    \n",
        "    model = XGBRegressor(\n",
        "        random_state=fold,\n",
        "        n_jobs=4,\n",
        "        n_estimators=5000,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
        "    \n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_test_predictions.append(test_preds)\n",
        "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))\n",
        "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
        "final_valid_predictions.columns = [\"id\", \"pred_2\"]\n",
        "final_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n",
        "\n",
        "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
        "sample_submission.columns = [\"id\", \"pred_2\"]\n",
        "sample_submission.to_csv(\"test_pred_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "PgBal4E66AFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_folds.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "\n",
        "df1 = pd.read_csv(\"train_pred_1.csv\")\n",
        "df2 = pd.read_csv(\"train_pred_2.csv\")\n",
        "\n",
        "df_test1 = pd.read_csv(\"test_pred_1.csv\")\n",
        "df_test2 = pd.read_csv(\"test_pred_2.csv\")\n",
        "\n",
        "df = df.merge(df1, on=\"id\", how=\"left\")\n",
        "df = df.merge(df2, on=\"id\", how=\"left\")\n",
        "\n",
        "df_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\n",
        "df_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "7xoSk_0M6jXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "useful_features = [\"pred_1\", \"pred_2\"]\n",
        "df_test = df_test[useful_features]\n",
        "\n",
        "final_predictions = []\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    model = LinearRegression()\n",
        "    model.fit(xtrain, ytrain)\n",
        "    \n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_predictions.append(test_preds)\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))"
      ],
      "metadata": {
        "id": "tG8KPvVi6vQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\n",
        "sample_submission.to_csv(\"submission_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "GyQCurLk60WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking"
      ],
      "metadata": {
        "id": "q3uYqz5d5FGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "bckYgoEz5PZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_folds.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "df1 = pd.read_csv(\"/content/train_pred_1.csv\")\n",
        "df1.columns = [\"id\", \"pred_1\"]\n",
        "df2 = pd.read_csv(\"/content/train_pred_2.csv\")\n",
        "df2.columns = [\"id\", \"pred_2\"]\n",
        "df3 = pd.read_csv(\"/content/train_pred_3.csv\")\n",
        "df3.columns = [\"id\", \"pred_3\"]\n",
        "df4 = pd.read_csv(\"/content/train_pred_4.csv\")\n",
        "df4.columns = [\"id\", \"pred_4\"]\n",
        "df5 = pd.read_csv(\"/content/train_pred_5.csv\")\n",
        "df5.columns = [\"id\", \"pred_5\"]\n",
        "\n",
        "df_test1 = pd.read_csv(\"/content/test_pred_1.csv\")\n",
        "df_test1.columns = [\"id\", \"pred_1\"]\n",
        "df_test2 = pd.read_csv(\"/content/test_pred_2.csv\")\n",
        "df_test2.columns = [\"id\", \"pred_2\"]\n",
        "df_test3 = pd.read_csv(\"/content/test_pred_3.csv\")\n",
        "df_test3.columns = [\"id\", \"pred_3\"]\n",
        "df_test4 = pd.read_csv(\"/content/test_pred_4.csv\")\n",
        "df_test4.columns = [\"id\", \"pred_4\"]\n",
        "df_test5 = pd.read_csv(\"/content/test_pred_5.csv\")\n",
        "df_test5.columns = [\"id\", \"pred_5\"]\n",
        "\n",
        "df = df.merge(df1, on=\"id\", how=\"left\")\n",
        "df = df.merge(df2, on=\"id\", how=\"left\")\n",
        "df = df.merge(df3, on=\"id\", how=\"left\")\n",
        "df = df.merge(df4, on=\"id\", how=\"left\")\n",
        "df = df.merge(df5, on=\"id\", how=\"left\")\n",
        "\n",
        "df_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\n",
        "df_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n",
        "df_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n",
        "df_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\n",
        "df_test = df_test.merge(df_test5, on=\"id\", how=\"left\")"
      ],
      "metadata": {
        "id": "UENY3nvD7Oql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "fz4IfJSe7fqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
        "df_test = df_test[useful_features]\n",
        "\n",
        "final_test_predictions = []\n",
        "final_valid_predictions = {}\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "\n",
        "    valid_ids = xvalid.id.values.tolist()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "\n",
        "    params = {\n",
        "        'random_state': 1, \n",
        "        'booster': 'gbtree',\n",
        "        'n_estimators': 7000,\n",
        "        'learning_rate': 0.03,\n",
        "        'max_depth': 2\n",
        "    }\n",
        "    \n",
        "    model = XGBRegressor(\n",
        "        n_jobs=4,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_test_predictions.append(test_preds)\n",
        "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))\n",
        "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
        "final_valid_predictions.columns = [\"id\", \"pred_1\"]\n",
        "final_valid_predictions.to_csv(\"level1_train_pred_1.csv\", index=False)\n",
        "\n",
        "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
        "sample_submission.columns = [\"id\", \"pred_1\"]\n",
        "sample_submission.to_csv(\"level1_test_pred_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "yWrnXO9Y7gIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
        "df_test = df_test[useful_features]\n",
        "\n",
        "final_test_predictions = []\n",
        "final_valid_predictions = {}\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "\n",
        "    valid_ids = xvalid.id.values.tolist()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    model = RandomForestRegressor(n_estimators=500, n_jobs=-1, max_depth=3)\n",
        "    model.fit(xtrain, ytrain)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_test_predictions.append(test_preds)\n",
        "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))\n",
        "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
        "final_valid_predictions.columns = [\"id\", \"pred_2\"]\n",
        "final_valid_predictions.to_csv(\"level1_train_pred_2.csv\", index=False)\n",
        "\n",
        "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
        "sample_submission.columns = [\"id\", \"pred_2\"]\n",
        "sample_submission.to_csv(\"level1_test_pred_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "SksuPWyX7oD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
        "df_test = df_test[useful_features]\n",
        "\n",
        "final_test_predictions = []\n",
        "final_valid_predictions = {}\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "\n",
        "    valid_ids = xvalid.id.values.tolist()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    model = GradientBoostingRegressor(n_estimators=500, max_depth=3)\n",
        "    model.fit(xtrain, ytrain)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_test_predictions.append(test_preds)\n",
        "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))\n",
        "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
        "final_valid_predictions.columns = [\"id\", \"pred_3\"]\n",
        "final_valid_predictions.to_csv(\"level1_train_pred_3.csv\", index=False)\n",
        "\n",
        "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
        "sample_submission.columns = [\"id\", \"pred_3\"]\n",
        "sample_submission.to_csv(\"level1_test_pred_3.csv\", index=False)"
      ],
      "metadata": {
        "id": "qsgpIznw7ztf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train_folds.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "\n",
        "df1 = pd.read_csv(\"level1_train_pred_1.csv\")\n",
        "df2 = pd.read_csv(\"level1_train_pred_2.csv\")\n",
        "df3 = pd.read_csv(\"level1_train_pred_3.csv\")\n",
        "\n",
        "df_test1 = pd.read_csv(\"level1_test_pred_1.csv\")\n",
        "df_test2 = pd.read_csv(\"level1_test_pred_2.csv\")\n",
        "df_test3 = pd.read_csv(\"level1_test_pred_3.csv\")\n",
        "\n",
        "df = df.merge(df1, on=\"id\", how=\"left\")\n",
        "df = df.merge(df2, on=\"id\", how=\"left\")\n",
        "df = df.merge(df3, on=\"id\", how=\"left\")\n",
        "\n",
        "df_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\n",
        "df_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n",
        "df_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xiUKDl088BSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\n",
        "df_test = df_test[useful_features]\n",
        "\n",
        "final_predictions = []\n",
        "scores = []\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest = df_test.copy()\n",
        "\n",
        "    ytrain = xtrain.target\n",
        "    yvalid = xvalid.target\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    \n",
        "    model = LinearRegression()\n",
        "    model.fit(xtrain, ytrain)\n",
        "    \n",
        "    preds_valid = model.predict(xvalid)\n",
        "    test_preds = model.predict(xtest)\n",
        "    final_predictions.append(test_preds)\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n",
        "    scores.append(rmse)\n",
        "\n",
        "print(np.mean(scores), np.std(scores))"
      ],
      "metadata": {
        "id": "ZeqFpGyk8Hp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\n",
        "sample_submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "W7K2myw_8KdT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}